\chapter{Implementation Tools}%
\label{chapter:tools}

As defined earlier in section~\ref{section:Goals}, the primary goal of this dissertation is to leverage the Human-Robot Collaboration \ac{HRC} paradigm by integrating \ac{MR} technologies alongside robot capabilities to enhance remote collaboration. In order to achieve this, a conceptual model is further implemented.

\section{Conceptual Model}
In order to start addressing the mentioned challenges, a first effort has been made. A robotic arm from Universal Robots, UR10e, shown in the figure \ref{f:ur10e_iris}, available at IRIS LAB, was used as a dynamic agent to assist in shared activities.
%  add a footnote to the robot model in universal robots website

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\linewidth]{figs/ur10e.jpeg}
    \caption{Robot UR10e used for the development of the dissertation work, available at IRIS-LAB, University of Aveiro}
    \label{f:ur10e_iris}
\end{figure}


\section{Digital Model Implementation of the Robot}
\label{section:digital-model}

\subsection{Unity}

Unity is a dynamic and versatile game engine developed by Unity Technologies \footnote{Unity Technologies \url{https://unity.com/} Accessed: 2024-09-30}, widely recognized for revolutionizing game development over the past few years. Beyond gaming, it has become a prominent tool for creating \ac{AR}, \ac {VR}, and \ac{MR} applications. Its user-friendly interface empowers developers to rapidly craft immersive experiences while simplifying complex development processes.

By offering an \ac{IDE} that combines \ac{GUI} manipulation of scene objects with a code editor, similar to Visual Studio, it allows developers to build virtual scenes by either creating or integrating 2D and 3D assets as well as apply attributes such as lighting, audio, physics properties, animations, and interactive gameplay logic. Afterwards, these composed scenes come to life, rendering them in real-time at frame rates that create smooth motion and immersive experiences.

One of Unity's significant advantages is its extensive platform compatibility. It supports development for various operating systems, including Windows, and Linux, as well as mobile platforms like iOS and Android. Additionally, a wide range of devices spanning \ac{AR},\ac{VR},\ac{MR} technologies are supported.

Unity's choice for developing the \ac{MR} application was advised by both supervisors regarding its versatility as well as its robust capabilities and extensive feature set.

\subsection{Digital Robot Model - URDF Importer Package}
% \input{chapters/on-site/digital-model} - commented this part because text is below - choose whether to use this or the text below

    % foi necessário encontrar um modelo do robot a ser utilizado - UR10e que se encontra no IRIS lab
    To successfully develop the \ac{MR} application for controlling the UR10e robot, it was essential to identify a model that closely mirrors 
    the actual robot. The Unity Robotics Hub \footnote{Unity Robotics Hub \url{https://github.com/Unity-Technologies/Unity-Robotics-Hub} 
    Accessed: 2024-02-02} facilitates the integration of robotics into Unity projects via the URDF-Importer package 
    \footnote{Unity URDF Importer \url{https://github.com/Unity-Technologies/URDF-Importer} Accessed: 2024-02-02}. 
    
    However, instead of importing the UR10e \textit{.urdf} model into the Unity environment, a UR10 model, sourced from a GitHub repository \footnote{PositronicsLab \url{https://github.com/PositronicsLab/reveal_packages/tree/master/industrial_arm/scenario/models/urdf/ur10} Accessed: 2024-02-05} 
    was used, due to its resemblance to the UR10e robot. 
    % This was discussed with the educators overseeing the dissertation development, and it was agreed that this approach would not pose any issues.


% \ac{MR} alongside a static robotic arm (UR10e) to support remote collaboration scenarios. This involves transforming human-robotic collaboration by integrating \ac{MR} technologies and robotic capabilities to enhance both on-site and remote collaboration experiences.

% Unity 3D engine will allow robot model development, enabling detailed and interactive digital twins with bilateral communication capabilities. By utilizing Vuforia for precise pose registration, the system ensures accurate spatial alignment between the virtual and physical robots.

% To enhance user awareness and prevent accidents, the system will implement visual and audio cues within the \ac{AR} environment, including safety-zone interactions and audio alerts. These features provide intuitive feedback to users, improving situational awareness during human--robot collaboration. The robot manipulation interface will be designed to be user-friendly, allowing non-expert users to operate the robot remotely using a handheld device (\ac{HHD}). This accessibility ensures that a wider range of users can effectively interact with the robotic system without extensive training.

% Real-time updates of the robot's position and workspace visualization will be provided through camera feed transmission, offering remote users a comprehensive view of the operational environment. This feature addresses the limitations identified in existing literature, where remote users often lack sufficient context and visibility of the workspace.

% % Furthermore, the proposed system will address challenges identified in the state-of-the-art review, such as networking latency and positioning accuracy. By implementing optimized communication protocols and advanced tracking algorithms, the system aims to ensure efficient and safe human--robot collaboration. These improvements will not only enhance the performance of the system but also contribute valuable insights to the field, bridging the gap between on-site and remote interaction capabilities in industrial applications.

% Overall, this project seeks to expand upon current research by providing a holistic solution that integrates advanced technologies to facilitate seamless collaboration between humans and robots, regardless of physical location. By focusing on both on-site and remote users, the system aims to enhance flexibility, safety, and efficiency in various industrial scenarios.

\section{Pose registration}

After having successfully imported the \ac{URDF} model of the real robot into the Unity environment, the next step was to ensure that the digital model was accurately aligned with the physical robot. 

\subsection{Vuforia}
\label{section:marker-detection}
% \input{chapters/on-site/marker-detection} commented this part because text is below - choose whether to use this or the text below

This alignment was achieved by utilizing Vuforia, a software platform that enables the creation of \ac{AR} experiences. Integrated with Unity, Vuforia simplifies the incorporation of \ac{AR} into mobile and digital apps. It uses computer vision technologies to recognize and track images and objects in the real world, allowing developers to overlay digital content precisely.

\subsection{Marker Detection}

The marker illustrated in Figure \ref{f:aruco_marker}, demonstrated greater stability, enabling the precise positioning of the digital UR10 model in alignment with the physical surroundings. Its choice followed initial attempts that yielded inconsistent results while using some other ArUco generated examples \footnote{ArUco Markers Generator \url{https://chev.me/arucogen/} Accessed: 2024-09-30}. 

To scan the physical environment around the robot, the camera shown in the figure \ref{fig:camera-c922} was used throughout the features' development process. 

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=0.7\textwidth]{figs/calib_io_charuco_200x150_5x7_25_18_DICT_4X4.png}
    \caption{ArUco marker used to allow the segmentation for aligning the digital twin accordingly to the real environment}
    \label{f:aruco_marker}
    \end{subfigure}
        \hfill % This command adds space between the subfigures
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=0.7\linewidth]{figs/camera-c922.jpg}
        \caption{Logitech c922 camera, used for on-site integration}
        \label{fig:camera-c922}
    \end{subfigure}
    \caption{ArUco marker used with the Logitech c922 camera for segmentation and manipulation of virtual environment}
\label{marker-camera}
\end{figure}

Consequently, both the ArUco marker and the Logitech c922 camera allowed to overlay the digital UR10 model on top of the physical robot.
% enhancing the integration of virtual and real-world elements - use???????

In the figure \ref{f:ur10_marker_unity} it is possible to see the digital UR10 model positioned related to the aruco marker. 
    (\ref{f:aruco_marker}), in a simulated Unity environment.
    \begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{figs/robot_marker_unity.jpg}
    \caption{Digital UR10 model related to the aruco marker, on Unity environment}
    \label{f:ur10_marker_unity}
    \end{figure}

\section{Billateral Communication}

\subsection{UR10e ROS Documentation}
Unity was chosen for its interactive capabilities, but this choice introduced additional complexity due to the need to operate across different operating systems—Windows for Unity and Ubuntu 20.04 for ROS Noetic, the version supporting the required ROS packages.

A key advantage was the existence of pre-existing resources from the IRIS Lab, where the robot is housed. Specifically, there were two GitHub repositories—\href{https://github.com/iris-ua/iris_sami}{iris\_sami} and \href{https://github.com/iris-ua/iris_ur10e}{iris\_ur10e}. These provided a well-established ROS environment, enabling control of the UR10e robot through RViz, trajectory planning, and real-time execution. \texttt{iris\_ur10e} package is integral to operating the physical robot in the lab, while \texttt{iris\_sami} allows for the robotic arm's manipulation.

Given this existing ROS setup on Ubuntu 20.04, ROS-TCP-Connector and ROS-TCP-Endpoint packages from the Unity Robotics Hub (\href{https://github.com/Unity-Technologies/ROS-TCP-Connector}{Unity-Technologies/ROS-TCP-Connector}) were used to establish the Wi-fi Connection. 

The proposed framework for both laptops connection is shown in figure. (add a figure of the framework proposed).


% Selecting this package over other ROS-Unity bridges was recommended by João Alves, one of the instructors who provided valuable insights during the development of this project.


\subsection{Message Generation}

By having already established the communication between Unity and ROS, specific types of messages from ROS environment had to be exchanged between the network, therefore enabling the robot to be controlled remotely.

After understanding that the ROS topic responsible for publishing the current state of the robot's joints was \texttt{/joint\_states}, these data needed to be sent to Unity. By adapting the already existing Unity Robotics Hub packages, these messages were not only successfully exchanged between the two environments, but also saved into a \texttt{.json} file for further manipulation.







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% from chatgpt - see it and check whether it makes sense or not the use this part instead of the above one (previous version of it)

introduction to implementation tools, unity game engine, vuforia for pose registration, urdf importer for unity, robot operating system, aruco marker for robot alignment, networking and protocols, conclusion

\chapter{Implementation Tools}%
\label{chapter:tools}

As introduced in section~\ref{section:Goals}, the primary objective of this dissertation is to explore and implement the concept of Human-Robot Collaboration (\ac{HRC}) by leveraging Mixed Reality (\ac{MR}) technologies. To achieve this goal, a comprehensive framework integrating hardware and software components is designed, facilitating remote collaboration in real-time. This chapter outlines the critical tools used in the implementation of the digital twin, as well as the hardware and software resources required for bi-directional robot control.

\section{Conceptual Model}
The implementation began by using the UR10e robotic arm (figure \ref{f:ur10e_iris}), housed at the IRIS Lab, as the core physical entity in this human-robot collaborative system. The UR10e robot served as the dynamic agent for performing collaborative tasks, where its physical attributes were mirrored in a digital environment, establishing a fundamental digital twin concept.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\linewidth]{figs/ur10e.jpeg}
    \caption{UR10e Robot used in the IRIS-LAB, University of Aveiro}
    \label{f:ur10e_iris}
\end{figure}

\section{Digital Model Implementation of the Robot}
\label{section:digital-model}

\subsection{Unity}
Unity, a widely recognized game engine developed by Unity Technologies, was selected as the primary platform for the \ac{MR} environment. Beyond its gaming origins, Unity has gained prominence for developing interactive 3D applications, particularly in \ac{AR}, \ac{VR}, and \ac{MR}. Unity's versatility in creating immersive simulations, coupled with its ability to integrate external data, made it a suitable choice for developing a digital twin for the UR10e robot.

By leveraging its integrated development environment (\ac{IDE}), Unity supports rapid prototyping of both virtual environments and \ac{MR} interfaces. The platform is compatible with multiple hardware interfaces and supports real-time rendering of 3D models. The Unity-based environment facilitates not only remote robot control but also the visualization of real-world robotic tasks in an augmented setting.

\subsection{Digital Robot Model - URDF Importer Package}
To mirror the UR10e robot in Unity, the Universal Robot Description Format (\ac{URDF}) was essential. Unity Robotics Hub's URDF Importer package was used to import the robot’s CAD model into the simulation environment \footnote{Unity Robotics Hub \url{https://github.com/Unity-Technologies/Unity-Robotics-Hub} Accessed: 2024-02-02}. However, due to the complexity of importing the UR10e model directly, a closely related UR10 model was used from an open-source repository \footnote{PositronicsLab \url{https://github.com/PositronicsLab/reveal_packages/tree/master/industrial_arm/scenario/models/urdf/ur10} Accessed: 2024-02-05}. 

This digital model laid the groundwork for performing bidirectional communication between the physical and digital environments. Integrating this URDF model allowed for real-time visualization of robot movements within the Unity environment, providing a key foundation for developing the digital twin.

\section{Pose Registration}
Pose registration is a crucial step in aligning the digital model with the physical robot. In this project, Vuforia, a cutting-edge \ac{AR} software platform, was integrated with Unity to accomplish this alignment.

\subsection{Vuforia}
\label{section:marker-detection}
Vuforia offers robust solutions for recognizing and tracking objects in real-world environments, which is crucial in Mixed Reality applications. In this project, Vuforia was used to recognize and track an ArUco marker placed on the physical robot, thus allowing the precise alignment of the digital robot model with its real counterpart.

\subsection{Marker Detection}
The ArUco marker (figure \ref{f:aruco_marker}) served as a fiducial marker for accurate pose estimation of the robot within the Unity environment. The Logitech c922 camera (figure \ref{fig:camera-c922}) scanned the marker, enabling the system to overlay the digital model accurately over the physical UR10. This ensured precise positioning and manipulation of the digital twin in the MR space, crucial for ensuring the success of bidirectional communication between the physical and digital models.

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=0.7\textwidth]{figs/calib_io_charuco_200x150_5x7_25_18_DICT_4X4.png}
    \caption{ArUco marker for alignment of the digital twin}
    \label{f:aruco_marker}
    \end{subfigure}
        \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=0.7\linewidth]{figs/camera-c922.jpg}
        \caption{Logitech c922 camera used for marker detection}
        \label{fig:camera-c922}
    \end{subfigure}
    \caption{Marker and camera setup for digital and physical robot alignment}
\label{marker-camera}
\end{figure}

In figure \ref{f:ur10_marker_unity}, the successful pose registration is demonstrated, where the digital UR10 model is shown in the Unity environment, precisely aligned with the ArUco marker and the physical robot.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{figs/robot_marker_unity.jpg}
    \caption{Digital UR10 model aligned with ArUco marker in Unity}
    \label{f:ur10_marker_unity}
\end{figure}

\section{Bidirectional Communication}

\subsection{UR10e ROS Documentation}
While Unity was chosen for its ability to create immersive environments, ROS (Robot Operating System) was selected to facilitate communication between the physical robot and its digital twin. The UR10e robot runs on ROS Noetic, which was configured on Ubuntu 20.04. By using ROS-TCP-Connector and ROS-TCP-Endpoint packages \footnote{Unity ROS Connector \url{https://github.com/Unity-Technologies/ROS-TCP-Connector} Accessed: 2024-02-02}

