\chapter{Conclusion and Future Work}%

\section{Conclusion}

This dissertation has explored the development of an \ac{MR}-assisted, \ac{DT}-enabled robot collaborative system with human-in-the-loop control. The primary objective consisted on enhancing \ac{HRC} by integrating advanced technologies that bridge the gap between physical and virtual environments supporting remote collaboration and, thereby, fostering more efficient and intuitive interactions in manufacturing settings.

On-Site interaction was a crucial aspect of the project. By utilizing \ac{HHD} such as tablets and smartphones, on-site participants are able to share live views of their surroundings. Furthermore, \ac{AR} elements were layed upon the \ac{MR} application to provide visual and audio cues with the purpose enhancing user's awareness. 

In terms of remote visualization and interaction, a foundational 2D interface was accessible via standard devices like laptops. This \ac{UI} aims to enable remote participants to visualize the collaboration scenario and understand the task context effectively. Furthermore, the system's capabilities allow remote operation of the robot through the \ac{MR} application, given that bidirectional communication was implemented. This enhancement empowered remote users to interact with and manipulate the collaborative environment, bringing them closer to the on-site experience, aiming to improve the overall collaborative efficacy.


*TODO: remove we
Regarding immersion, a camera was mounted on the robot to automate the process of environment sharing with remote participants. This feature relieved on-site participants from the responsibility of manually sharing visual information, as the robot could now autonomously provide live feeds of the workspace. This automation not only improved efficiency but also enhanced the immersive experience for remote users by offering real-time visual insights into the operational environment.

Throughout the development process, we leveraged the Unity game engine for robot model development and employed the Robot Operating System for seamless communication between the physical robot and its \ac{DT}. The use of Vuforia facilitated precise pose registration, ensuring accurate alignment between virtual and physical models. By integrating both visual and audio cues as well as intuitive controls within the shared environment, we enhanced user awareness of the robot's movements and provided a user-friendly interface for robot manipulation.

In conclusion, the project successfully achieved its main objectives by developing a system that integrates \ac{MR} and \ac{DT} technologies to enhance \ac{HRC}, particularly focusing on the remote participant's capabilities. While direct studies were not conducted to evaluate usability, the implemented functionalities suggest that, with further refinement and user-centered adjustments, the system holds potential to improve the intuitiveness, efficiency, and safety of collaborative environments. Future evaluations and iterative improvements will help align the system more closely with the principles of Industry 5.0, advancing human-centric and flexible industrial practices.


*TODO: ver questao de manipular o robot atraves de mover a garra para um ponto em especifico e o robot fazer a cinematica inversa sozinho

\section{Future Work}

Despite having achieved its primary goals, there are several areas for future exploration to further enhance the system's capabilities and impact.
% organize below part
Future work related to this includes:

\begin{itemize}
    \item \textbf{Enhancing Immersive Technologies}: Exploring the potential of advanced devices like the Microsoft HoloLens 2 for the on-site member and Meta Quest for the remote user can significantly enhance the immersive experience of remote collaboration. Integrating \ac{MR} headsets enables spatial awareness, allowing the HoloLens 2 to map and understand the physical environment, providing more precise interactions. Combined with enhanced object manipulation and real-time data integration, users can interact intuitively within the collaborative environment, overlaying critical information and executing complex tasks with precision. 
    For the remote user, Meta Quest provides immersive visualization, allowing them to fully engage with 3D content in a virtual space. Its mobility allows the remote user to work from different locations seamlessly. Immersive collaboration tools such as whiteboard sharing and 3D model manipulation enable richer, real-time teamwork, further boosting collaborative efficiency. 
    \item \textbf{Improving Communication Tools}: Integrating advanced communication tools such as interactive annotations on 3D models and gesture-based interaction will further enhance collaboration between on-site and remote participants. Remote users can annotate specific areas on the digital twin in real time, providing clear, visual instructions to the on-site member. Gesture-based interaction, meanwhile, offers both users a more intuitive, natural means of communication, allowing for non-verbal cues and actions. However, this approach must be adapted to the specific requirements of each use case, as varying tasks may demand different levels of precision, feedback, or interaction.
    \item \textbf{Conducting User Study:} is a critical step to refine the system based on real-world usage feedback and performance metrics. By carrying out comprehensive usability studies, we can evaluate different aspects of the system separately, such as \ac{UI} design, robot control modes, and task execution. This will help identify key points and areas for improvement. Furthermore, analyzing task performance data will allow us to optimize workflows, improve system ergonomics, and enhance overall efficiency, ensuring that the system is tailored to meet users' diverse needs.
    \item \textbf{Longitudinal Studies and Ergonomic}: Evaluating the long-term impact of the developed system on collaboration efficiency and user well-being is essential. Longitudinal studies can assess how the technology influences productivity, identifying trends that inform further improvements. Additionally, ergonomic assessments will ensure that \ac{AR} devices do not cause discomfort or health issues, optimizing long-term usage for user well-being. 
\end{itemize}

In addition to user experience research, future work could focus on:

\begin{itemize} 

    \item \textbf{Advanced Interaction Modalities}: Incorporating gesture recognition and voice commands can make the system more accessible and reduce reliance on manual input devices. These modalities can provide a more intuitive control mechanism, especially in environments where traditional input devices are impractical.
    
    \item \textbf{Security and Privacy Measures}: Strengthening encryption and authentication protocols will protect user data and ensure secure communication channels. This is crucial for maintaining trust and compliance with data protection regulations.
\end{itemize}

By pursuing these future developments, the system can significantly improve its effectiveness and user satisfaction. Continuous refinement based on user feedback and technological advancements could contribute to its adoption in various industrial contexts, ultimately enhancing \ac{HRC} and advancing the principles of Industry 5.0.

\section{Final Remarks}

This dissertation has laid the groundwork for addressing \ac{HRC} in manufacturing environments. By integrating \ac{MR} and \ac{DT} technologies, we have successfully created a system that may enhance human performance and efficient, as well as enhance collaboration between users physicall distributted through the use of a new reality. The insights gained and the foundation established through this work pave the way for future explorations that can further bridge the gap between humans and machines. Embracing continuous improvement and adaptation will ensure that such systems remain relevant and impactful in the ever-evolving landscape of industrial automation.