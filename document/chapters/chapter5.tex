\chapter{Discussion and Evaluation}

In this section, I will provide a critical discussion and evaluation of the developed \ac{MR} environment, implemented in Unity, as part of this dissertation's objectives.

The primary goal of this project consists on enhancing remote collaboration between human operators by utilizing a robotic arm (UR10e) and \ac{MR}. In order to achieve this, a framework allowing for an interactive, fully functional \ac{MR} application that facilitate bidirectional communication between the robot and its \ac{DT} was developed. It features a friendly \ac{UI} that enables the visualization and control of the robotic arm, where the \ac{DT} was designed to respond in real-time to the robot's physical movements, and vice versa. The achieved bidirectional communication ensures that the \ac{MR} system operates not as a mere digital shadow of the robot but as a true \ac{DT}, capable of reflecting and influencing the physical entity.

One of the key features developed was a seamless control method integrated within the \ac{MR} environment, allowing the user to manipulate the robot via the \ac{UI}. This interface includes joint selection buttons, directional controls, and toggle switches for precise manipulation of each robotic joint.  This setup enabled users to control the robot's movements via through the \ac{MR} interface and send this position update to the \ac{ROS} middleware, with real-time synchronization ensuring the robot accurately mirrors the \ac{DT}'s state after the publication of control commands.

A critical enhancement to the user experience was the development of two safety zones integrated into the \ac{UI}. These zones are designed to improve user safety and operational awareness when interacting with the robot in real-time. Upon entering the "Outer Safety Zone", which has a bigger radius, an visual alarm starts beeping and it triggers a color change in the "Inner Safety Zone" indicating that the user is approaching the robot's workspace. Whenever this "Inner Safety Zone" is breached, an auditory alerts plays until the user leaves this hazardous area, ensuring the user understands the potential danger. This feature is crucial for preventing accidents and ensuring user safety during robot operation.
Visual alerts such as color changes, combined with auditory warnings, enhance the immersive experience and ensure that users are aware of potential dangers while operating the robot. However, it must be noted that the accuracy of these safety zones is contingent upon the proper alignment of the camera with the \ac{AR} marker, as any misalignment impacts the precision of distance measurement.
% rewrite the part

Another significant addition was the implementation of a live camera feed, allowing a remote participant to view the robot’s workspace in real-time. This feed is crucial for remote collaboration, enabling users from different locations to have a synchronized understanding of the robot’s surroundings. The camera feed is transmitted from the \ac{ROS} middleware to the Unity \ac{MR} environment via \ac{TCP}/\ac{IP} after image compression. Compression was necessary due to the substantial bandwidth required for raw video data transmission. This feature offers an important perspective for remote users, aiding in monitoring and providing assistance when necessary.

Both the joint control interface and the safety-zone mechanisms were designed to be toggled on/off, thereby ensuring that the user has the option to clear the \ac{UI} for an unobstructed view of the on-site environment.

\section{Challenges and Issues Faced}
%  continue here




Issues found during the development:

The following developed features, for enhancing the on-site environment, were tested while using a laptop with the previously described camera.
    % continue here"

    Despite many attempts, trying to build the \ac{MR} application into android handheld devices was not effective.
    Since the digital version of the robot showed physics limitations when entering on the simulation environment.


    However, due to the complexity of importing the UR10e model directly, a closely related UR10 model was used from an open-source repository \footnote{PositronicsLab \url{https://github.com/PositronicsLab/reveal_packages/tree/master/industrial_arm/scenario/models/urdf/ur10} Accessed: 2024-02-05}. 


    \subsubsection{Integration Highlights - relevant advantages}
    These two nodes addressed key aspects of system performance:
    \begin{itemize}
        \item \textbf{Synchronization:} Ensures that changes in Unity’s control environment are accurately and timely reflected in the robot's physical movements.
        \item \textbf{Modularity:} Separates data handling and robot control into different nodes to improve system reliability and ease of maintenance.
    \end{itemize}


    \subsection{Real-Time Data Transmission Challenges and Solutions}

    One of the main challenges in transmitting real-time video data to the Unity environment was the limitation of bandwidth over Wi-Fi. Transmitting uncompressed video data would lead to latency issues, impeding smooth real-time visualization. By employing the \texttt{image\_transport} package to compress the video stream, we significantly reduced the data size, enabling efficient transmission. The compressed data was then successfully received and displayed in Unity with minimal latency, ensuring that remote users could monitor the robot’s environment in near real time.


    % use case scenario - from chat, change it
    \section{Use Case Scenario: Collaborative Robot-Assisted Assembly Task}
    \label{sec:use_case}
    
    To validate the application developed in this project, we propose a practical use case scenario in which a human-robot collaborative system is used to assist in a real-time assembly task. The scenario involves a remote user and an on-site operator working together to assemble a complex product, such as a LEGO structure, using the robotic arm UR10e to perform precise tasks like identifying, picking, and placing components.
    
    \subsection{Assembly Task Description}
    The task requires the human operator and the robotic arm to collaborate in assembling various parts of the product. The on-site user prepares the workspace by organizing components and configuring the robot, while the remote user oversees the assembly process and directly controls the robot's movements via the \ac{MR} interface. The robot, equipped with a mounted camera, captures a live video feed of the workspace, streamed to the remote participant in real time. This video allows the remote user to see exactly what the robot is observing, thus ensuring precise actions for component identification, manipulation, and placement.
    
    \subsection{Features Utilized in the Assembly Process}
    
    \begin{itemize}
        \item \textbf{On-Site and Remote Collaboration:} The \ac{MR}-based system allows both the on-site and remote users to collaboratively control and monitor the robot’s actions. The on-site operator can use the developed \ac{HHD} interface for fine-tuning the robot’s movements, while the remote user manipulates the robot using the virtual interface, synchronizing real-world and digital movements.
        
        \item \textbf{Digital Twin (\ac{DT}) Synchronization:} The \ac{DT} of the UR10e, aligned through Vuforia using ArUco markers, ensures that both the remote and on-site members are consistently aware of the robot’s state. Any movement of the robot, either from remote commands or physical interactions, is accurately mirrored in the Unity-based \ac{MR} interface.
    
        \item \textbf{Real-time Video Streaming:} The live camera feed mounted on the UR10e arm streams a real-time video of the robot’s workspace to the remote user, providing full visual context of the assembly task. This reduces the burden on the on-site operator to manually share visual information, allowing the remote user to have a direct perspective of the task and make adjustments as needed.
    
        *TODO: correct this part 
        \item \textbf{Safety Zones:} Despite the developed virtual safety zones, displayed in the \ac{MR} interface, being more relevant for the on-site user to prevent collisions during robot operation, these can be easily modified regarding the use-case scenario described. Instead of halting its movement if the on-site member enters the robot working area, visual and auditory alerts are triggered, improving the safety of the interaction. The robot will automatically halt if it detects an on-site user breaching the predefined zones, preventing potential accidents.
    
        \item \textbf{Bidirectional Control and Feedback:} The bilateral communication established through ROS-TCP Connector allows commands from the remote user to be executed in real time by the robot, and the robot’s state is reflected back to the digital environment. This ensures that the robot follows precise trajectories, and real-time feedback from the ROS environment ensures synchronization between the virtual and physical models.
    
        \item \textbf{Camera Feed Transmission:} The camera feed enhances situational awareness for the remote participant, who can directly monitor the assembly process through the robot’s perspective. This feature reduces the cognitive load on the on-site operator, enabling the remote user to make real-time decisions regarding component handling and placement, ultimately improving task efficiency.
    
    \end{itemize}
    
    \subsection{Potential Industrial Applications}
    
    This human-robot collaborative system has wide-ranging applications in several industries that rely on precise assembly tasks:
    
    \begin{itemize}
        \item \textbf{Electronics Manufacturing:} In industries such as electronics manufacturing, where delicate components need to be assembled with high precision, the system could be applied to remotely assemble small and fragile parts. The real-time video feed and \ac{MR} interface would ensure that the remote operator has full visibility of the workspace, while the robot performs tasks requiring high precision, like picking and placing tiny components.
    
        \item \textbf{Automotive Assembly:} In automotive production, remote technicians could assist on-site workers in installing or assembling complex parts. For example, during the assembly of engines or electric vehicle batteries, the robot could handle heavy or dangerous components while the human operator provides real-time guidance from a safe distance.
    
        \item \textbf{Aerospace Component Assembly:} Aerospace applications often involve complex, high-value assemblies where precision is critical. The collaborative system could enable engineers to remotely guide robotic arms to fit components with tight tolerances, reducing human error and improving task consistency.
    
        \item \textbf{Medical Device Manufacturing:} In medical device manufacturing, this system could ensure the safe and precise assembly of small, intricate parts, where any mistake could be costly. Remote experts could oversee the assembly process, while robots assist in handling and assembling the delicate components of surgical instruments or diagnostic devices.
    
    \end{itemize}
    
    \subsection{Advantages of the System}
    The integration of the developed \ac{MR}-based system into such industrial applications offers several advantages:
    
    \begin{itemize}
        \item \textbf{Enhanced Remote Collaboration:} The real-time synchronization between the digital twin and physical robot, combined with live camera feeds, allows remote experts to have full control over assembly tasks without being physically present, enabling global collaboration.
        
        \item \textbf{Improved Efficiency and Precision:} The ability to delegate repetitive or precision-dependent tasks to the robot, while the human focuses on higher-level decision-making, improves overall task efficiency. The \ac{MR} interface provides a more intuitive control mechanism than traditional robotic interfaces.
        
        \item \textbf{Safety:} The implementation of virtual safety zones and real-time feedback mechanisms ensures that human workers remain safe while working closely with robots. This reduces the risk of accidents in high-risk environments such as automotive and aerospace manufacturing.
    
        \item \textbf{Cost-Effective and Scalable:} By enabling remote operation, the system reduces the need for on-site presence, minimizing travel costs and downtime. It is also scalable across multiple sites, allowing experts to manage operations in various locations without needing to be physically present.
    
    \end{itemize}
    
    In summary, this use case scenario illustrates the practical value of the developed features in collaborative human-robot assembly tasks. The combination of real-time robot manipulation, live video streaming, and digital twin synchronization offers a powerful toolset for modern industrial environments, enhancing productivity, safety, and collaboration.
    